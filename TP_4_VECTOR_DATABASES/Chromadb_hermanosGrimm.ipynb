{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pr√°ctica Chromabd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 1Ô∏è‚É£ Importar librer√≠as\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import os\n",
    "import numpy as np\n",
    "import uuid\n",
    "\n",
    "# Modelo de embeddings\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "def get_embeddings(text):\n",
    "    return model.encode(text).tolist()\n",
    "\n",
    "# Inicializar ChromaDB con persistencia\n",
    "client = chromadb.PersistentClient(path=\"./chroma_store\")\n",
    "collection = client.get_or_create_collection(name=\"documentos_ia\")\n",
    "\n",
    "def cargar_documentos():\n",
    "    docs_path = \"docs/\"\n",
    "    documentos = []\n",
    "    metadatos = []\n",
    "    ids = []\n",
    "\n",
    "    for filename in os.listdir(docs_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(docs_path, filename), 'r', encoding=\"utf-8\") as f:\n",
    "                text = f.read().strip()\n",
    "                chunks = [text[i:i+500] for i in range(0, len(text), 500)]\n",
    "                \n",
    "                for i, chunk in enumerate(chunks):\n",
    "                    documentos.append(chunk)\n",
    "                    metadatos.append({\"source\": filename})\n",
    "                    ids.append(str(uuid.uuid4()))  # ID √∫nico\n",
    "    \n",
    "    return documentos, metadatos, ids\n",
    "\n",
    "def crear_base_datos():\n",
    "    docs, metas, ids = cargar_documentos()\n",
    "    embeddings = [get_embeddings(d) for d in docs]\n",
    "    collection.add(documents=docs, embeddings=embeddings, metadatas=metas, ids=ids)\n",
    "    print(\"‚úÖ Base de datos creada con √©xito.\")\n",
    "\n",
    "# --- CRUD FUNCIONES ---\n",
    "\n",
    "def create_example(new_doc):\n",
    "    \"\"\"A√±adir un documento nuevo\"\"\"\n",
    "    embedding = get_embeddings(new_doc)\n",
    "    doc_id = str(uuid.uuid4())\n",
    "    metadata = {\"source\": \"nuevo_documento.txt\"}\n",
    "    \n",
    "    collection.add(\n",
    "        documents=[new_doc],\n",
    "        embeddings=[embedding],\n",
    "        metadatas=[metadata],\n",
    "        ids=[doc_id]\n",
    "    )\n",
    "    print(f\"‚úÖ Documento a√±adido con ID: {doc_id}\")\n",
    "\n",
    "def read_example(query):\n",
    "    \"\"\"Consultar documentos similares\"\"\"\n",
    "    query_emb = get_embeddings(query)\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_emb],\n",
    "        n_results=1\n",
    "    )\n",
    "    \n",
    "    if results[\"documents\"]:\n",
    "        print(f\"üìÑ Mejor coincidencia: {results['documents'][0][0]}\")\n",
    "        print(f\"üìÅ Fuente: {results['metadatas'][0][0]['source']}\")\n",
    "        print(f\"üÜî ID: {results['ids'][0][0]}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No se encontraron resultados.\")\n",
    "\n",
    "def get_documents_by_id(doc_id):\n",
    "    \"\"\"Obtener un documento por ID\"\"\"\n",
    "    results = collection.get(ids=[doc_id], include=[\"documents\", \"metadatas\", \"embeddings\"])\n",
    "    \n",
    "    if results[\"documents\"]:\n",
    "        print(f\"üìÑ Documento: {results['documents'][0]}\")\n",
    "        print(f\"üìÅ Fuente: {results['metadatas'][0]['source']}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Documento no encontrado.\")\n",
    "\n",
    "def update_example(old_id, new_text):\n",
    "    \"\"\"Actualizar un documento (eliminar y reinsertar)\"\"\"\n",
    "    collection.delete(ids=[old_id])\n",
    "    \n",
    "    new_id = str(uuid.uuid4())\n",
    "    embedding = get_embeddings(new_text)\n",
    "    metadata = {\"source\": \"documento_actualizado.txt\"}\n",
    "    \n",
    "    collection.add(\n",
    "        documents=[new_text],\n",
    "        embeddings=[embedding],\n",
    "        metadatas=[metadata],\n",
    "        ids=[new_id]\n",
    "    )\n",
    "    print(f\"‚ôªÔ∏è Documento actualizado. Nuevo ID: {new_id}\")\n",
    "\n",
    "def delete_example(doc_id):\n",
    "    \"\"\"Eliminar por ID\"\"\"\n",
    "    collection.delete(ids=[doc_id])\n",
    "    print(f\"üóëÔ∏è Documento con ID '{doc_id}' eliminado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Base de datos creada con √©xito.\n"
     ]
    }
   ],
   "source": [
    "crear_base_datos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.get(include=[\"embeddings\", \"documents\", \"metadatas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: cce8b633-0e76-4958-a2b2-f7d471579083, Contenido: Hab√≠a una vez, en un reino lejano, una joven llamada Cenicienta, quien viv√≠a con su madrastra y herm  Metadata: {'source': 'doc1.txt'} Embedding: [0.03695862367749214, 0.09123437851667404, -0.006070955656468868, -0.12097117304801941, -0.08920404314994812]...\n",
      "ID: 7a719259-97b1-4c4f-8ae5-dde12cae83a4, Contenido: siosas por impresionar al pr√≠ncipe, se prepararon con lujosos vestidos y joyas, pero dejaron a Cenic  Metadata: {'source': 'doc1.txt'} Embedding: [0.006394681986421347, 0.08617572486400604, -0.0019227326847612858, -0.05962548404932022, -0.061944372951984406]...\n",
      "ID: ed7b7a7e-8dd1-424c-91e7-2116ac773acf, Contenido: a huy√≥ dejando atr√°s uno de sus zapatos de cristal.\n",
      "\n",
      "El pr√≠ncipe, decidido a encontrarla, recorri√≥ e  Metadata: {'source': 'doc1.txt'} Embedding: [-0.03151360899209976, 0.08306147158145905, -0.07771097123622894, -0.01462840661406517, -0.08390384167432785]...\n",
      "ID: eba282bb-919b-45d6-b22b-8cc323f4da24, Contenido: Hab√≠a una vez un rey y una reina que, despu√©s de muchos a√±os de esperar, tuvieron una hija a quien l  Metadata: {'source': 'doc2.txt'} Embedding: [-0.03492216765880585, 0.08479011058807373, 0.0005371668376028538, 0.009881743229925632, 0.001516307587735355]...\n",
      "ID: 47e54375-b18a-40a1-9373-2b1d691cd469, Contenido: itar el destino, el d√≠a lleg√≥ y, mientras jugaba en el castillo, Aurora encontr√≥ una rueca y, al pin  Metadata: {'source': 'doc2.txt'} Embedding: [-0.06446028500795364, 0.07546401023864746, 0.018588189035654068, -0.023814106360077858, -0.0333498939871788]...\n",
      "ID: 93f3e612-5bc5-487d-8e88-043025f12751, Contenido: spert√≥, y con ella despertaron todos los habitantes del reino. Aurora y Felipe se casaron y vivieron  Metadata: {'source': 'doc2.txt'} Embedding: [0.012801522389054298, 0.03525477647781372, -0.008599805645644665, 0.05228067561984062, -0.02984979934990406]...\n",
      "ID: 1efadffc-7c21-4b7b-b273-eefbc6b10272, Contenido: En un bosque oscuro y denso, viv√≠an dos ni√±os llamados Hansel y Gretel con su padre y madrastra. La   Metadata: {'source': 'doc3.txt'} Embedding: [-0.013025358319282532, 0.05160713940858841, 0.012255487963557243, -0.015589126385748386, -0.034816645085811615]...\n",
      "ID: 8d1cd695-ba60-4920-a571-179df2bc083e, Contenido: los llev√≥ nuevamente al bosque, esta vez sin dejarles piedras para seguir. Esta vez, Hansel y Gretel  Metadata: {'source': 'doc3.txt'} Embedding: [0.013411472551524639, 0.036447152495384216, 0.004563669208437204, -0.06315571069717407, -0.061769917607307434]...\n",
      "ID: 90b4d867-73e4-422b-a223-c6ac7b062aeb, Contenido:  en el horno para cocinarlo, pero Gretel, astuta, empuj√≥ a la bruja al horno y la mat√≥. Los ni√±os to  Metadata: {'source': 'doc3.txt'} Embedding: [0.08238028734922409, 0.013966620899736881, 0.003906174562871456, -0.0040484098717570305, -0.055914465337991714]...\n"
     ]
    }
   ],
   "source": [
    "for id, content, metadata, embedding in zip(results[\"ids\"], results[\"documents\"], results[\"metadatas\"], results[\"embeddings\"]):\n",
    "    print(f\"ID: {id}, Contenido: {content[:100]} \", f\"Metadata: {metadata}\", f\"Embedding: {embedding[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Crear y Consultar \n",
    "Crea un documento nuevo con el texto: \"La zorra y el gato iban caminando juntos por el bosque, y comenzaron a hablar sobre lo que har√≠an si los atacaban los perros de caza. La zorra se jactaba de tener muchas estrategias, mientras que el gato dec√≠a que solo conoc√≠a una: trepar a un √°rbol para escapar\". \n",
    "Realiza una consulta para encontrar documentos similares a la frase: \"Cuando hay peligro, algunos animales prefieren escapar trepando antes que confiar en planes complicados\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Documento a√±adido con ID: cff757f7-c547-43e2-9cdd-2c946ec0d821\n"
     ]
    }
   ],
   "source": [
    "new_doc = \"Hab√≠a una vez un lobo malvado que asustaba a todos los animales del bosque. Un d√≠a encontr√≥ a una astuta zorra que lo enga√±√≥ para salvarse.\"\n",
    "\n",
    "create_example(new_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Mejor coincidencia: Hab√≠a una vez un lobo malvado que asustaba a todos los animales del bosque. Un d√≠a encontr√≥ a una astuta zorra que lo enga√±√≥ para salvarse.\n",
      "üìÅ Fuente: nuevo_documento.txt\n",
      "üÜî ID: cff757f7-c547-43e2-9cdd-2c946ec0d821\n"
     ]
    }
   ],
   "source": [
    "query = \"Un lobo enga√±oso y una zorra astuta en el bosque.\"\n",
    "\n",
    "read_example(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¬øQu√© tipo de operaci√≥n CRUD usaste primero?\n",
    "\n",
    "La primera operaci√≥n utilizada fue la \"C\" de Create.\n",
    "\n",
    "### ¬øCu√°l es el ID del documento creado?\n",
    "\n",
    "Documento a√±adido con ID: cff757f7-c547-43e2-9cdd-2c946ec0d821\n",
    "\n",
    "### Explica por qu√© el documento aparece como coincidencia en la consulta.\n",
    "\n",
    "La consulta fue:\n",
    "\n",
    "> \"Cuando hay peligro, algunos animales prefieren escapar trepando antes que confiar en planes complicados.\"\n",
    "\n",
    "El documento aparece como la mejor coincidencia en la consulta porque el texto de la consulta (\"Un lobo enga√±oso y una zorra astuta en el bosque\") es muy similar al contenido del documento creado, que habla del lobo y la zorra en el bosque. La similitud sem√°ntica entre las palabras clave (\"lobo\", \"zorra\", \"bosque\", \"enga√±√≥\") y el contexto general hace que el sistema lo considere como una coincidencia relevante.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Actualizar y Eliminar \n",
    "Crea un documento con el texto: \"Hab√≠a una vez un lobo malvado que asustaba a todos los animales del bosque.\" \n",
    "\n",
    "Encuentra su ID, luego actual√≠zalo por: \"Un lobo astuto enga√±√≥ a los animales del bosque para conseguir lo que quer√≠a.\"\n",
    "\n",
    "Elimina el documento original usando el mismo ID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Documento a√±adido con ID: 46f6ce7f-c9af-4340-b7e3-e601d505b4ec\n"
     ]
    }
   ],
   "source": [
    "new_doc2 = \"Hab√≠a una vez un lobo malvado que asustaba a todos los animales del bosque.\"\n",
    "\n",
    "create_example(new_doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ôªÔ∏è Documento actualizado. Nuevo ID: 9d94e31f-d9f7-41d3-8210-bef6376fa077\n"
     ]
    }
   ],
   "source": [
    "new_text = \"Un lobo astuto enga√±√≥ a los animales del bosque para conseguir lo que quer√≠a.\"\n",
    "old_id = \"46f6ce7f-c9af-4340-b7e3-e601d505b4ec\"\n",
    "\n",
    "update_example(old_id, new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¬øQu√© ocurre si intentas actualizar un documento eliminado? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Delete of nonexisting embedding ID: 46f6ce7f-c9af-4340-b7e3-e601d505b4ec\n",
      "Delete of nonexisting embedding ID: 46f6ce7f-c9af-4340-b7e3-e601d505b4ec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ôªÔ∏è Documento actualizado. Nuevo ID: 0ea43c9d-05bf-4a74-b1f4-fcdecc27f6d2\n"
     ]
    }
   ],
   "source": [
    "update_example(old_id, new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la funci√≥n `update_example`, la operaci√≥n de actualizaci√≥n consiste en **eliminar un documento por su ID** y luego **insertar uno nuevo con contenido actualizado**.\n",
    "\n",
    "Si intent√°s actualizar un documento que **ya fue eliminado anteriormente**, la operaci√≥n `collection.delete(ids=[old_id])` simplemente **no encuentra nada que eliminar**, y **no genera un error cr√≠tico**. Esto es esperado, ya que muchas implementaciones de bases de datos vectoriales manejan estas situaciones de forma tolerante, permitiendo operaciones idempotentes (es decir, que se puedan repetir sin cambiar el resultado)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¬øC√≥mo se garantiza la integridad de los datos en las operaciones? \n",
    "\n",
    "La integridad de los datos se garantiza mediante:\n",
    "\n",
    "1. **IDs √∫nicos:** Cada documento tiene un `id` √∫nico (en este caso generado con `uuid.uuid4()`), lo que evita colisiones o sobrescrituras accidentales.\n",
    "2. **Eliminaci√≥n expl√≠cita:** Al eliminar antes de insertar, evitamos que haya duplicados no deseados del mismo contenido modificado.\n",
    "3. **Control de metadatos:** Al usar campos como `\"source\"` dentro de `metadata`, se puede rastrear el origen y estado del documento, incluso despu√©s de ser actualizado.\n",
    "4. **Uso de embeddings consistentes:** Cada nuevo documento se vectoriza al momento de ser insertado, lo que asegura que su representaci√≥n sem√°ntica est√© alineada con su contenido actual.\n",
    "\n",
    "Este enfoque de \"eliminar y reinsertar\" es simple pero efectivo para garantizar consistencia en bases de datos vectoriales que no siempre permiten operaciones `update` nativas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Errores y Validaci√≥n \n",
    "Intenta eliminar un documento con el ID \"no_existe\". \n",
    "\n",
    "Crea un nuevo documento sin usar get_embeddings() (ejemplo: enviar un array vac√≠o). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Delete of nonexisting embedding ID: no_existe\n",
      "Delete of nonexisting embedding ID: no_existe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Documento con ID 'no_existe' eliminado.\n"
     ]
    }
   ],
   "source": [
    "delete_example(\"no_existe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\chromadb\\db\\mixins\\embeddings_queue.py\", line 308, in _notify_one\n",
      "    sub.callback(filtered_embeddings)\n",
      "  File \"c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\chromadb\\segment\\impl\\vector\\local_persistent_hnsw.py\", line 211, in _write_records\n",
      "    self._ensure_index(len(records), len(record[\"embedding\"]))\n",
      "  File \"c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\chromadb\\segment\\impl\\vector\\local_hnsw.py\", line 208, in _ensure_index\n",
      "    raise InvalidDimensionException(\n",
      "chromadb.errors.InvalidDimensionException: Dimensionality of (0) does not match indexdimensionality (384)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\caro_\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\logging\\__init__.py\", line 1110, in emit\n",
      "    msg = self.format(record)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\caro_\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\logging\\__init__.py\", line 953, in format\n",
      "    return fmt.format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\caro_\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\logging\\__init__.py\", line 687, in format\n",
      "    record.message = record.getMessage()\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\caro_\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\logging\\__init__.py\", line 377, in getMessage\n",
      "    msg = msg % self.args\n",
      "          ~~~~^~~~~~~~~~~\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\caro_\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\caro_\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\caro_\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3362, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3607, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3667, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\caro_\\AppData\\Local\\Temp\\ipykernel_8580\\1980874906.py\", line 2, in <module>\n",
      "    collection.add(\n",
      "  File \"c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py\", line 99, in add\n",
      "    self._client._add(ids, self.id, embeddings, metadatas, documents)\n",
      "  File \"c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\chromadb\\api\\segment.py\", line 249, in _add\n",
      "    self._producer.submit_embeddings(coll[\"topic\"], records_to_submit)\n",
      "  File \"c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\chromadb\\db\\mixins\\embeddings_queue.py\", line 165, in submit_embeddings\n",
      "    self._notify_all(topic_name, embedding_records)\n",
      "  File \"c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\chromadb\\db\\mixins\\embeddings_queue.py\", line 287, in _notify_all\n",
      "    self._notify_one(sub, embeddings)\n",
      "  File \"c:\\Proyectos\\UBA\\VectorDatabases\\basesdatosIA\\Lib\\site-packages\\chromadb\\db\\mixins\\embeddings_queue.py\", line 312, in _notify_one\n",
      "    logger.error(\n",
      "Message: 'Exception occurred invoking consumer for subscription 1d09dbe7-5c8a-4353-9f96-5c2bdb70941ato topic persistent://default/default/9d7b44e6-4e14-4dd8-b4a3-0b324088d4a0'\n",
      "Arguments: (InvalidDimensionException('Dimensionality of (0) does not match indexdimensionality (384)'),)\n"
     ]
    }
   ],
   "source": [
    "# Crear un documento sin usar get_embeddings()\n",
    "collection.add(\n",
    "    documents=[\"Texto sin embedding\"],\n",
    "    embeddings=[[]],  # array vac√≠o\n",
    "    metadatas=[{\"source\": \"sin_embedding.txt\"}],\n",
    "    ids=[str(uuid.uuid4())]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¬øQu√© errores ocurren en cada caso? \n",
    "\n",
    "- **Eliminar un documento con un ID inexistente:**\n",
    "\n",
    "  No se genera un error cr√≠tico. ChromaDB simplemente ignora el ID si no existe en la colecci√≥n. Este comportamiento es **idempotente y seguro**, lo que permite hacer m√∫ltiples intentos de eliminaci√≥n sin afectar la integridad de la base.\n",
    "\n",
    "- **Agregar un documento sin `get_embeddings()` (por ejemplo, con una lista vac√≠a):**\n",
    "\n",
    "  Se genera un **`ValueError` o `RuntimeError`**, dependiendo del backend utilizado. Esto ocurre porque el sistema espera un **vector num√©rico v√°lido**, y un array vac√≠o no cumple con ese requisito. La operaci√≥n falla al intentar procesar el embedding inv√°lido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¬øC√≥mo prevenir estos problemas? \n",
    "\n",
    "- Para evitar errores al eliminar documentos, se recomienda verificar previamente si el ID existe en la colecci√≥n. Esto evita realizar operaciones innecesarias o confusas sobre documentos inexistentes.\n",
    "\n",
    "- Para prevenir fallos al agregar documentos, es fundamental asegurarse de que los embeddings se hayan generado correctamente y que no est√©n vac√≠os. Validar este paso garantiza que el sistema reciba datos en el formato esperado y evita errores en tiempo de ejecuci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: Consultas por Tema \n",
    "Crea tres documentos: \n",
    "* \"La madrastra malvada de Blanca Nieves y su plan oculto\" \n",
    "* \"La bruja de Hansel y Gretel y su trampa mortal\" \n",
    "* \"El lobo de Caperucita Roja y su enga√±o mal√©volo\" \n",
    "\n",
    "Realiza una consulta por la frase: \"Villanos de los cuentos de los Hermanos Grimm\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Documento a√±adido con ID: 2d5fc8ad-8d87-4bc9-bb05-c229bb676ca2\n",
      "‚úÖ Documento a√±adido con ID: 096a7602-356f-4b92-b0bf-1bf7e98fa9b5\n",
      "‚úÖ Documento a√±adido con ID: 5487cf39-ea1c-4975-bfce-03a9106372f1\n"
     ]
    }
   ],
   "source": [
    "doc1 = \"La madrastra malvada de Blanca Nieves y su plan oculto\" \n",
    "doc2 = \"La bruja de Hansel y Gretel y su trampa mortal\" \n",
    "doc3 = \"El lobo de Caperucita Roja y su enga√±o mal√©volo\" \n",
    "\n",
    "create_example(doc1)\n",
    "create_example(doc2)\n",
    "create_example(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Mejor coincidencia: La bruja de Hansel y Gretel y su trampa mortal\n",
      "üìÅ Fuente: nuevo_documento.txt\n",
      "üÜî ID: 096a7602-356f-4b92-b0bf-1bf7e98fa9b5\n"
     ]
    }
   ],
   "source": [
    "consulta = \"Villanos de los cuentos de los Hermanos Grimm\"\n",
    "read_example(consulta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¬øCu√°les documentos aparecen como coincidencias? \n",
    "\n",
    "**\"La bruja de Hansel y Gretel y su trampa mortal\"** fue identificado como la mejor coincidencia, lo que tiene sentido, dado que la consulta est√° enfocada en villanos, y la bruja es uno de los villanos m√°s emblem√°ticos de los cuentos de los Hermanos Grimm.\n",
    "\n",
    "### Analiza c√≥mo las palabras clave influyen en los resultados.\n",
    "\n",
    "La raz√≥n de esta coincidencia puede ser que las palabras clave de la consulta \"villanos\", \"trampa\", y \"mortal\" est√°n estrechamente relacionadas con el contexto de la bruja en la historia, que es conocida por su papel de antagonista.\n",
    "\n",
    "Los otros villanos como la madrastra de Blanca Nieves y el lobo de Caperucita Roja no coincidieron tan bien probablemente debido a que sus descripciones o palabras clave no se ajustaron tan estrechamente a las especificaciones de la consulta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5: Eliminaciones Selectivas \n",
    "Crea dos documentos con t√≥picos opuestos (ejemplo: uno sobre \"Ecolog√≠a\" y otro sobre \n",
    "\"Miner√≠a de datos\"). \n",
    "\n",
    "Elimina el documento sobre ecolog√≠a usando su ID. \n",
    "\n",
    "Verifica que solo quede un documento. \n",
    "\n",
    "¬øC√≥mo usar collection.count() para confirmar? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos los conceptos de \"magia\" y \"realidad\" como temas opuestos dentro de los cuentos. Uno puede hablar sobre \"magia\" (como algo fant√°stico y sobrenatural), y el otro sobre \"realidad\" (como los aspectos m√°s mundanos y reales de la vida cotidiana)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Documento a√±adido con ID: 1110d7b5-6c6c-45cf-aff6-153795d5f196\n",
      "‚úÖ Documento a√±adido con ID: 5fe5741d-986b-4c3f-a29a-8692be3f8072\n"
     ]
    }
   ],
   "source": [
    "create_example(\"La magia esta presente en los cuentos\")\n",
    "create_example(\"Los personajes de los cuentos viven una realida muy dura\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de documentos en la colecci√≥n: 21\n"
     ]
    }
   ],
   "source": [
    "count = collection.count()\n",
    "print(f\"Cantidad de documentos en la colecci√≥n: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Documento con ID '1110d7b5-6c6c-45cf-aff6-153795d5f196' eliminado.\n"
     ]
    }
   ],
   "source": [
    "# Se eliminara el documento relacionado con la magia.\n",
    "\n",
    "id_magia = \"1110d7b5-6c6c-45cf-aff6-153795d5f196\"\n",
    "delete_example(id_magia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de documentos restantes en la colecci√≥n: 20\n"
     ]
    }
   ],
   "source": [
    "count = collection.count()\n",
    "print(f\"Cantidad de documentos restantes en la colecci√≥n: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6: Actualizaci√≥n en Cadena \n",
    "\n",
    "Crea un documento con el texto \"Los dilemas morales en los cuentos de los Hermanos Grimm\". \n",
    "\n",
    "Actual√≠zalo dos veces: \n",
    "* Primera actualizaci√≥n: \"El sacrificio de los ni√±os en Hansel y Gretel y el dilema de la supervivencia\" \n",
    "* Segunda actualizaci√≥n: \"Las consecuencias de las decisiones de los villanos en los cuentos de Cenicienta y Blanca Nieves\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Documento a√±adido con ID: a30a9c40-05ba-4004-8ce0-2bcfcaf3ea39\n"
     ]
    }
   ],
   "source": [
    "create_example(\"Los dilemas morales en los cuentos de los Hermanos Grimm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ôªÔ∏è Documento actualizado. Nuevo ID: 5676225e-b563-4c56-a38e-0023b5524829\n"
     ]
    }
   ],
   "source": [
    "id_doc_inicial = \"a30a9c40-05ba-4004-8ce0-2bcfcaf3ea39\"\n",
    "update_example(id_doc_inicial, \"El sacrificio de los ni√±os en Hansel y Gretel y el dilema de la supervivencia\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Delete of nonexisting embedding ID: a30a9c40-05ba-4004-8ce0-2bcfcaf3ea39\n",
      "Delete of nonexisting embedding ID: a30a9c40-05ba-4004-8ce0-2bcfcaf3ea39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ôªÔ∏è Documento actualizado. Nuevo ID: a4a246e3-a59d-40a9-a173-788404eac98e\n"
     ]
    }
   ],
   "source": [
    "# Segunda actualizaci√≥n: hablar sobre las consecuencias de las decisiones morales en los cuentos\n",
    "update_example(id_doc_inicial, \"Las consecuencias de las decisiones de los villanos en los cuentos de Cenicienta y Blanca Nieves\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¬øC√≥mo sigue evolucionando el contenido del documento con cada update? \n",
    "\n",
    "El documento empieza con una visi√≥n general de los dilemas morales en los cuentos, luego se especializa en un caso espec√≠fico y, finalmente, aborda las consecuencias morales a lo largo de varios cuentos.\n",
    "\n",
    "Este proceso refleja c√≥mo el contenido del documento se actualiza en cadena, pasando de un tema general a uno m√°s detallado y espec√≠fico, para finalmente cubrir un conjunto m√°s amplio de ejemplos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 7: Consultas Ambiguas \n",
    "Crea dos documentos similares pero no id√©nticos: \n",
    "* \"Blanca Nieves era la m√°s hermosa del reino\" \n",
    "* \"La reina pregunt√≥ qui√©n era la m√°s hermosa\". \n",
    "\n",
    "Realiza una consulta por \"La m√°s hermosa\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Documento a√±adido con ID: 9adaf7fa-15f9-48e5-b22a-a8888e19b571\n",
      "‚úÖ Documento a√±adido con ID: aa5bc130-1726-4a2e-bac0-bd80b77e3943\n"
     ]
    }
   ],
   "source": [
    "create_example(\"Blanca Nieves era la m√°s hermosa del reino\")\n",
    "create_example(\"La reina pregunt√≥ qui√©n era la m√°s hermosa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Mejor coincidencia: La reina pregunt√≥ qui√©n era la m√°s hermosa\n",
      "üìÅ Fuente: nuevo_documento.txt\n",
      "üÜî ID: aa5bc130-1726-4a2e-bac0-bd80b77e3943\n"
     ]
    }
   ],
   "source": [
    "read_example(\"La m√°s hermosa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¬øAmbos documentos aparecen? \n",
    "\n",
    "No, solamente aparecio el 2er texto guardado. Eso indica que, ChromaDB identific√≥ mayor similitud sem√°ntica con ese documento que con el otro.\n",
    "\n",
    "### Explica la similitud sem√°ntica. \n",
    "\n",
    "Ambas frases comparten el mismo concepto central: el reconocimiento de qui√©n es la m√°s hermosa dentro del reino.\n",
    "Sin embargo, est√°n formuladas de manera diferente:\n",
    "\n",
    "* Una es una afirmaci√≥n directa sobre Blanca Nieves.\n",
    "\n",
    "* La otra es una pregunta indirecta relacionada con la reina.\n",
    "\n",
    "Aunque no hay coincidencia textual exacta entre la consulta \"La m√°s hermosa\" y la frase completa \"La reina pregunt√≥ qui√©n era la m√°s hermosa\", el modelo pudo reconocer que ambas tratan el mismo significado.\n",
    "\n",
    "El hecho de que ese segundo documento haya sido la mejor coincidencia, indica que el motor valor√≥ m√°s el contexto sem√°ntico en que aparece la expresi√≥n \"la m√°s hermosa\" (dentro de una estructura narrativa)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 8: Reiniciar Base de Datos \n",
    "Elimina todos los documentos usando delete() con el par√°metro correcto. \n",
    "\n",
    "Vuelve a cargar la base desde cero con crear_base_datos(). \n",
    "\n",
    "¬øCu√°ntos documentos hay ahora? (Usa collection.count()). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de documentos en la colecci√≥n: 24\n"
     ]
    }
   ],
   "source": [
    "count = collection.count()\n",
    "print(f\"Cantidad de documentos en la colecci√≥n: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.delete(where={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Base de datos creada con √©xito.\n"
     ]
    }
   ],
   "source": [
    "crear_base_datos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de documentos en la colecci√≥n: 9\n"
     ]
    }
   ],
   "source": [
    "count = collection.count()\n",
    "print(f\"Cantidad de documentos en la colecci√≥n: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 9: Errores de Inserci√≥n \n",
    "Intenta crear un documento sin texto (ejemplo: cadena vac√≠a). \n",
    "\n",
    "Corrige el error usando la funci√≥n get_embeddings()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Documento a√±adido con ID: 3dc7a66d-d7e8-4c3f-a5cc-9dbdc4d6308d\n"
     ]
    }
   ],
   "source": [
    "create_example(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Documento: \n",
      "üìÅ Fuente: nuevo_documento.txt\n"
     ]
    }
   ],
   "source": [
    "get_documents_by_id(\"3dc7a66d-d7e8-4c3f-a5cc-9dbdc4d6308d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a funci√≥n create_example() permite a√±adir nuevos documentos a la base de datos utilizando un modelo de embeddings. Sin embargo, en su versi√≥n actual, no contiene ninguna validaci√≥n que impida insertar cadenas vac√≠as.\n",
    "\n",
    "Esto representa un problema, ya que:\n",
    "\n",
    "* Una cadena vac√≠a no aporta significado sem√°ntico.\n",
    "\n",
    "* Aunque el modelo de embeddings pueda generar un vector (por ejemplo, uno por defecto o casi nulo), este no representa informaci√≥n √∫til.\n",
    "\n",
    "* Se corre el riesgo de contaminar la base de datos con documentos irrelevantes o sin contenido.\n",
    "\n",
    "Para solucionar esto se deber√≠a agregar una validaci√≥n que verifique que el texto no est√© vac√≠o antes de generar el embedding e insertarlo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example(new_doc):\n",
    "    \"\"\"A√±adir un documento nuevo (con validaci√≥n de contenido)\"\"\"\n",
    "    if not new_doc.strip():\n",
    "        print(\"‚ùå Error: No se puede insertar un documento vac√≠o.\")\n",
    "        return\n",
    "\n",
    "    embedding = get_embeddings(new_doc)\n",
    "    doc_id = str(uuid.uuid4())\n",
    "    metadata = {\"source\": \"nuevo_documento.txt\"}\n",
    "\n",
    "    collection.add(\n",
    "        documents=[new_doc],\n",
    "        embeddings=[embedding],\n",
    "        metadatas=[metadata],\n",
    "        ids=[doc_id]\n",
    "    )\n",
    "    print(f\"‚úÖ Documento a√±adido con ID: {doc_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error: No se puede insertar un documento vac√≠o.\n"
     ]
    }
   ],
   "source": [
    "create_example(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¬øQu√© lecci√≥n aprendemos sobre los requisitos de ChromaDB?\n",
    "\n",
    "* Es responsabilidad del desarrollador validar el contenido de los documentos antes de insertarlos.\n",
    "\n",
    "* ChromaDB y los modelos de embeddings no siempre detendr√°n una inserci√≥n inv√°lida, especialmente si se proporciona un embedding num√©ricamente v√°lido.\n",
    "\n",
    "* Incluir controles de calidad y limpieza de datos mejora la consistencia y utilidad de la base vectorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio opcional: Retrieval-Augmented Generation \n",
    "\n",
    "Intente levantar un llm en un endpoint local con ollama o LMStudio. Utilice el llm para generar respuestas aumentadas con contexto similar a una consulta dada. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬øC√≥mo sigue esto?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### de forma conceptual debemos:\n",
    "1. Recuperar el contexto relevante con una busqueda como read_example(query) o similar.\n",
    "2. Formular el prompt para el llm, juntando la consulta original con los embeddings relevantes.\n",
    "3. Enviar la Petici√≥n al Endpoint (en este caso LM Studio).\n",
    "4. Recibir y mostrar la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Base de datos creada con √©xito.\n",
      "üë© Pregunta: ¬øPor qu√© Cenicienta no pudo ir al baile inicialmente?\n",
      "ü§ñ Respuesta de la IA: Cenicienta no pudo ir al baile inicialmente porque su madrastra y hermanastras malvadas le ordenaron que se quedara en casa. Estaban interesadas en impresionar al pr√≠ncipe, por lo que prepararon lujosos vestidos y joyas para asistir al baile, dejando a Cenicienta atr√°s.\n",
      "üë© Pregunta: ¬øQu√© ocurre cuando llega la medianoche en el baile?\n",
      "ü§ñ Respuesta de la IA: Cuando llega la medianoche en el baile, Cenicienta debe regresar a su casa, ya que el hechizo se rompe y ella vuelve a ser una simple sirvienta. Si no lo hace, continuar√° siendo m√°gicamente atrapada y congelada en un estado de p√©rdida de la forma humana.\n",
      "üë© Pregunta: ¬øQu√© hizo Mal√©fica al no ser invitada a la fiesta?\n",
      "ü§ñ Respuesta de la IA: Mal√©fica fue ofendida cuando el rey y la reina olvidaron invitarla a la celebraci√≥n de nacimiento de Aurora. Al no ser invitada, ella lanz√≥ una maldici√≥n contra Aurora, diciendo que cuando cumpliera 16 a√±os se pinchar√≠a el dedo con el huso de una rueca y caer√≠a en un profundo sue√±o que solo pod√≠a romperse con un beso verdaderamente amoroso.\n",
      "üë© Pregunta: ¬øQu√© pas√≥ con el reino mientras Aurora dorm√≠a?\n",
      "ü§ñ Respuesta de la IA: Mientras Aurora dorm√≠a, todo el reino entero se sumi√≥ en un letargo profundo. Todos los habitantes del reino, incluidos animales y plantas, quedaron dormidos en la misma situaci√≥n de reposo que Aurora. El reino permaneci√≥ as√≠ bajo el hechizo hasta que lleg√≥ el valiente pr√≠ncipe Felipe para rescatar a su prometida.\n",
      "\n",
      "El pr√≠ncipe Felipe viaj√≥ por un caminito peligroso y luch√≥ contra dragones en su camino hacia el castillo donde Aurora estaba retenida. A pesar de los numerosos obst√°culos, logr√≥ llegar al lugar donde la princesa dorm√≠a, junto con el reino.\n",
      "\n",
      "Cuando Felipe lleg√≥ al castillo, bes√≥ a Aurora, rompiendo as√≠ la terrible maldici√≥n lanzada por Malefica. As√≠, el reino sali√≥ del letargo y todos los habitantes recuperaron su energ√≠a y fueron despiertos, dej√°ndoles un recuerdo eterno de ese maravilloso evento en el que se hab√≠a convertido la vida dentro del reino mientras Aurora dorm√≠a.\n",
      "üë© Pregunta: ¬øQu√© hizo la bruja cuando atrap√≥ a Hansel y Gretel?\n",
      "ü§ñ Respuesta de la IA: La bruja meti√≥ a Hansel en una jaula y lo oblig√≥ a hacer todo el trabajo, mientras se aprovechaba de Gretel para realizar las tareas.\n",
      "üë© Pregunta: ¬øC√≥mo logr√≥ Gretel vencer a la bruja?\n",
      "ü§ñ Respuesta de la IA: Gretel venci√≥ a la bruja al impedir que la bruja metiera a Hansel en el horno para cocinarlo. La astuta Gretel empuj√≥ a la bruja dentro del horno, lo cual result√≥ fatal para ella. Esto demostr√≥ la valent√≠a y habilidad de Gretel al enfrentarse a la bruja malvada y salvaguardar la vida de su hermano Hansel.\n",
      "üë© Pregunta: ¬øC√≥mo se representan las figuras maternas en estos cuentos?\n",
      "ü§ñ Respuesta de la IA: En los dos cuentos que presentaste, la figura materna es fundamental para la trama. En \"Cenicienta\", la hada madrina aparece como una figura ben√©fica y protectora de Cenicienta. Le da un vestido hermoso y zapatos de cristal para que pueda asistir al baile del pr√≠ncipe, pero advierte a ella acerca de las consecuencias si no cumple con el tiempo establecido para regresar a su hogar. En este sentido, la figura materna es amiga, protectora y gu√≠a, aunque tambi√©n impone l√≠mites.\n",
      "\n",
      "Por otro lado, en \"Hansel y Gretel\", la figura materna es bastante negativa y cruel. Su madre y el padre de Hansel y Gretel abandonan a sus hijos en el bosque, no solo sin comida sino incluso plantando piedras para dificultar su camino. Es importante resaltar que esta figura materna act√∫a m√°s como un agente de peligro en lugar de protecci√≥n para los ni√±os.\n",
      "\n",
      "En resumen, la figura materna se representa como protectora y ben√©fica en \"Cenicienta\", pero como malvada y cruel en\n",
      "üë© Pregunta: ¬øQu√© lecciones morales ofrecen estas historias cl√°sicas?\n",
      "ü§ñ Respuesta de la IA: Estas historias cl√°sicas ofrecen varias lecciones morales:\n",
      "\n",
      "1. La bondad y el car√°cter son m√°s importantes que el exterior o las apariencias. Cenicienta, a pesar de vivir en condiciones dif√≠ciles, mantiene su bondad e integridad.\n",
      "\n",
      "2. Se debe ser aut√≥nomo y confiar en uno mismo. Aurora se enfrenta a numerosos desaf√≠os antes de encontrarse con el pr√≠ncipe Felipe y superar las dificultades juntos demuestra que no necesita ser rescatada por un h√©roe.\n",
      "\n",
      "3. El amor es capaz de superar cualquier obst√°culo, incluso maldiciones o hechizos. Al besarlo a Aurora, el pr√≠ncipe rompe la maldici√≥n y ella se despierta de su sue√±o profundo.\n",
      "\n",
      "4. La perseverancia y la resistencia pueden llevar a superar dificultades insuperables. El pr√≠ncipe Felipe lucha contra dragones y atraviesa numerosos obst√°culos para encontrar a Aurora, ilustrando c√≥mo es necesario emprender y continuar una b√∫squeda sin importar las dificultades.\n",
      "\n",
      "5. La justicia y la equidad\n",
      "üë© Pregunta: salir\n"
     ]
    }
   ],
   "source": [
    "# Esta secci√≥n es para la integraci√≥n con LM Studio y no es parte del CRUD. Es solo un ejemplo de c√≥mo se podr√≠a hacer una consulta a un modelo de lenguaje como Llama 3 o similar.\n",
    "# 2Ô∏è‚É£ Integraci√≥n con LM Studio (Llama 3 o similar)\n",
    "import requests\n",
    "import json\n",
    "\n",
    "LM_STUDIO_URL = \"http://127.0.0.1:1234/v1/chat/completions\"  \n",
    "\n",
    "def query_llama(prompt):\n",
    "    \"\"\"Envia un prompt a LM Studio y recibe la respuesta.\"\"\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"max_tokens\": 256, \n",
    "        # Es posible agregar otros par√°metros de generaci√≥n aca (temperature, top_p, etc.)\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(LM_STUDIO_URL, headers=headers, data=json.dumps(data))\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error al conectar con LM Studio: {e}\")\n",
    "        return None\n",
    "    except (KeyError, json.JSONDecodeError) as e:\n",
    "        print(f\"Error al procesar la respuesta de LM Studio: {e}\")\n",
    "        return None\n",
    "\n",
    "def responder_pregunta(pregunta):\n",
    "    \"\"\"Busca documentos relevantes y luego consulta a Llama.\"\"\"\n",
    "    query_emb = get_embeddings(pregunta)\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_emb],\n",
    "        n_results=3  # Obtener algunos documentos relevantes como contexto\n",
    "    )\n",
    "\n",
    "    if results[\"documents\"]:\n",
    "        contexto = \"\\n\\n\".join(results[\"documents\"][0])\n",
    "        prompt = f\"Bas√°ndote en la siguiente informaci√≥n:\\n\\n{contexto}\\n\\nResponde a la siguiente pregunta: {pregunta}\" # Juntar el contexto obtenido y la pregunta\n",
    "        respuesta = query_llama(prompt)\n",
    "        return respuesta\n",
    "    else:\n",
    "        return \"No se encontraron documentos relevantes para responder a tu pregunta.\"\n",
    "\n",
    "# --- Ejemplo de uso ---\n",
    "if __name__ == \"__main__\":\n",
    "    crear_base_datos() \n",
    "\n",
    "    while True:\n",
    "        pregunta_usuario = input(\"Preg√∫ntame algo sobre los documentos (o escribe 'salir'): \")\n",
    "        print(f\"üë© Pregunta: {pregunta_usuario}\")\n",
    "        if pregunta_usuario.lower() == 'salir':\n",
    "            break\n",
    "\n",
    "        respuesta_ia = responder_pregunta(pregunta_usuario)\n",
    "        if respuesta_ia:\n",
    "            print(f\"ü§ñ Respuesta de la IA: {respuesta_ia}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basesdatosIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
